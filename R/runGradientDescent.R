#' runGradientDescent
#' 
#' @keywords internal
#' @import futile.logger
#' 
#' @description Runner for gradient descent (or stochastic gradient descent) for
#' the specified number of epoch
#' 
#' @return a list containing two matrices generated by the gradient descent
runGradientDescent <- function(L0r10, R0r10, lambda, epochs, gamma=0.01, block,
                               nnzis, nnzjs, is, js, D, m , n, r) {
    flog.debug(paste("Calculating the gradient descent for block", block))
    LR <- list(L=L0r10, R=R0r10)
    
    loss_result <- loss(LR$L, LR$R, lambda, D = D)
    
    curLoss <- loss_result$loss
    error_matrix <- loss_result$error_matrix
    
    for (epoch in seq_len(epochs)) {
        flog.debug(paste("Calculating gradient descent epoch", epoch, "of", 
                         epochs, "for block", block))
        LR <- gdepoch(LR$L, LR$R, lambda, gamma, nnzis = nnzis, nnzjs = nnzjs, 
                      is = is, js = js, D = D)
        
        ## bold driver step size update
        oldLoss <- curLoss
        
        loss_result <- loss(LR$L, LR$R, lambda, D = D)
        
        curLoss <- loss_result$loss
        error_matrix <- loss_result$error_matrix
        if (oldLoss < curLoss) { 
            gamma <- gamma/2
        } else {
            gamma <- gamma * 1.05
        }
    }
    return(LR)
}